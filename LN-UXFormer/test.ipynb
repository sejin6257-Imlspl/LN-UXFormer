{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU 3\n",
      "Model loaded: /data3/glocal_project/LN_UXFormer/result_bestmodel/LN_UXFormer_epoch.pt\n",
      "Found 231 valid image pairs\n",
      "Skipped 0 pairs with empty masks\n",
      "Test dataset loaded: 231 images\n",
      "Starting evaluation... Total 15 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: torch.Size([16, 1, 224, 224])\n",
      "Target shape: torch.Size([16, 1, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:08<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Foreground Dice Score: 0.6227\n",
      "==================================================\n",
      "\n",
      "Segmentation results saved: /data3/glocal_project/LN_UXFormer/result_image\n",
      "\n",
      "Folder structure:\n",
      "├── input/           : Original input images\n",
      "├── target/          : Ground truth segmentation masks\n",
      "├── prediction/      : Predicted segmentation masks\n",
      "├── overlay_pred/    : Input + Prediction overlay (green)\n",
      "└── overlay_target/  : Input + Ground truth overlay (red)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "\n",
    "from data_load import Dataset\n",
    "from model.LN_UXFormer import LN_UXFormer\n",
    "\n",
    "\n",
    "def dice_coefficient(pred_mask, true_mask, smooth=1e-6):\n",
    "    pred_flat = pred_mask.reshape(-1)\n",
    "    target_flat = true_mask.reshape(-1)\n",
    "    \n",
    "    intersection = torch.sum(pred_flat * target_flat)\n",
    "    return (2.0 * intersection + smooth) / (torch.sum(pred_flat) + torch.sum(target_flat) + smooth)\n",
    "\n",
    "\n",
    "def calculate_binary_dice_score(pred, target, threshold=0.5):\n",
    "    pred_binary = (pred > threshold).float()\n",
    "    \n",
    "    target = target.contiguous()\n",
    "    pred_binary = pred_binary.contiguous()\n",
    "    \n",
    "    dice = dice_coefficient(pred_binary, target).item()\n",
    "    \n",
    "    return {'Foreground': dice}\n",
    "\n",
    "\n",
    "def save_segmentation_results(images, targets, outputs, batch_idx, batch_size, output_dir, dataset, threshold=0.5):\n",
    "    os.makedirs(os.path.join(output_dir, 'input'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'target'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'prediction'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'overlay_pred'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'overlay_target'), exist_ok=True)\n",
    "    \n",
    "    pred_sigmoid = torch.sigmoid(outputs)\n",
    "    pred_binary = (pred_sigmoid > threshold).float().cpu().numpy()\n",
    "    \n",
    "    for i in range(images.size(0)):\n",
    "        idx = batch_idx * batch_size + i\n",
    "        \n",
    "        if idx >= len(dataset):\n",
    "            break\n",
    "        \n",
    "        input_img = images[i, 0].cpu().numpy()\n",
    "        input_img = (input_img * 255).astype(np.uint8)\n",
    "        \n",
    "        target_mask = targets[i, 0].cpu().numpy()\n",
    "        pred_mask = pred_binary[i, 0]\n",
    "        \n",
    "        colors = {\n",
    "            'background': [0, 0, 0],\n",
    "            'foreground': [255, 255, 255],\n",
    "            'target_overlay': [255, 0, 0],\n",
    "            'pred_overlay': [0, 255, 0]\n",
    "        }\n",
    "        \n",
    "        target_rgb = np.zeros((target_mask.shape[0], target_mask.shape[1], 3), dtype=np.uint8)\n",
    "        pred_rgb = np.zeros((pred_mask.shape[0], pred_mask.shape[1], 3), dtype=np.uint8)\n",
    "        \n",
    "        target_rgb[target_mask > 0] = colors['foreground']\n",
    "        pred_rgb[pred_mask > 0] = colors['foreground']\n",
    "        \n",
    "        input_rgb = np.stack([input_img] * 3, axis=2)\n",
    "        \n",
    "        overlay_pred = input_rgb.copy()\n",
    "        pred_overlay_mask = pred_mask > 0\n",
    "        overlay_pred[pred_overlay_mask] = (overlay_pred[pred_overlay_mask] * 0.3 + \n",
    "                                          np.array(colors['pred_overlay']) * 0.7).astype(np.uint8)\n",
    "        \n",
    "        overlay_target = input_rgb.copy()\n",
    "        target_overlay_mask = target_mask > 0\n",
    "        overlay_target[target_overlay_mask] = (overlay_target[target_overlay_mask] * 0.3 + \n",
    "                                              np.array(colors['target_overlay']) * 0.7).astype(np.uint8)\n",
    "        \n",
    "        filename = f\"image_{idx:04d}\"\n",
    "        \n",
    "        Image.fromarray(input_img).save(os.path.join(output_dir, 'input', f\"{filename}.png\"))\n",
    "        Image.fromarray(target_rgb).save(os.path.join(output_dir, 'target', f\"{filename}.png\"))\n",
    "        Image.fromarray(pred_rgb).save(os.path.join(output_dir, 'prediction', f\"{filename}.png\"))\n",
    "        Image.fromarray(overlay_pred).save(os.path.join(output_dir, 'overlay_pred', f\"{filename}.png\"))\n",
    "        Image.fromarray(overlay_target).save(os.path.join(output_dir, 'overlay_target', f\"{filename}.png\"))\n",
    "\n",
    "\n",
    "def evaluate_test_set(model, test_loader, device, save_segmentation=False, output_dir=None, dataset=None, threshold=0.5):\n",
    "    model.eval()\n",
    "    dice_scores = []\n",
    "    \n",
    "    if save_segmentation and output_dir is not None:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Starting evaluation... Total {len(test_loader)} batches\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch_data in enumerate(tqdm(test_loader)):\n",
    "            images, targets = batch_data\n",
    "            \n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            try:\n",
    "                outputs = model(images)\n",
    "                if isinstance(outputs, tuple):\n",
    "                    outputs = outputs[0]\n",
    "                \n",
    "                if batch_idx == 0:\n",
    "                    print(f\"Model output shape: {outputs.shape}\")\n",
    "                    print(f\"Target shape: {targets.shape}\")\n",
    "                \n",
    "                dice_score = calculate_binary_dice_score(outputs, targets, threshold)\n",
    "                dice_scores.append(dice_score['Foreground'])\n",
    "                \n",
    "                if save_segmentation and output_dir is not None:\n",
    "                    save_segmentation_results(images, targets, outputs, batch_idx, test_loader.batch_size, output_dir, dataset, threshold)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing batch {batch_idx}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                if batch_idx == 0:\n",
    "                    raise\n",
    "    \n",
    "    mean_dice = np.mean(dice_scores)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Foreground Dice Score: {mean_dice:.4f}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if output_dir is not None:\n",
    "        with open(os.path.join(output_dir, 'evaluation_results.txt'), 'w') as f:\n",
    "            f.write(f\"Foreground Dice Score: {mean_dice:.4f}\\n\")\n",
    "            f.write(\"\\nSaved folders:\\n\")\n",
    "            f.write(\"- input: Original input images\\n\")\n",
    "            f.write(\"- target: Ground truth segmentation masks\\n\")\n",
    "            f.write(\"- prediction: Predicted segmentation masks\\n\")\n",
    "            f.write(\"- overlay_pred: Input + Prediction overlay (green)\\n\")\n",
    "            f.write(\"- overlay_target: Input + Ground truth overlay (red)\\n\")\n",
    "    \n",
    "    return mean_dice\n",
    "\n",
    "\n",
    "def main():\n",
    "    test_dir = '/data3/glocal_project/multiclass_seg_kid_ney/data/covid_test'\n",
    "    model_path = '/data3/glocal_project/LN_UXFormer/result_bestmodel/LN_UXFormer_epoch.pt'\n",
    "    gpu_id = 3\n",
    "    batch_size = 16\n",
    "    save_segmentation = True\n",
    "    output_dir = '/data3/glocal_project/LN_UXFormer/result_image'\n",
    "    threshold = 0.5\n",
    "    \n",
    "    if gpu_id >= 0 and torch.cuda.is_available():\n",
    "        device = torch.device(f\"cuda:{gpu_id}\")\n",
    "        print(f\"Using GPU {gpu_id}\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "    \n",
    "    try:\n",
    "        model = LN_UXFormer(n_channels=1, n_classes=1).to(device)\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint, strict=False)\n",
    "        print(f\"Model loaded: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        test_dataset = Dataset(test_dir)\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=4,\n",
    "            pin_memory=True if device.type == 'cuda' else False\n",
    "        )\n",
    "        print(f\"Test dataset loaded: {len(test_dataset)} images\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        mean_dice = evaluate_test_set(\n",
    "            model, test_loader, device,\n",
    "            save_segmentation, output_dir, test_dataset,\n",
    "            threshold\n",
    "        )\n",
    "        \n",
    "        if save_segmentation:\n",
    "            print(f\"\\nSegmentation results saved: {output_dir}\")\n",
    "            print(\"\\nFolder structure:\")\n",
    "            print(\"├── input/           : Original input images\")\n",
    "            print(\"├── target/          : Ground truth segmentation masks\")\n",
    "            print(\"├── prediction/      : Predicted segmentation masks\")\n",
    "            print(\"├── overlay_pred/    : Input + Prediction overlay (green)\")\n",
    "            print(\"└── overlay_target/  : Input + Ground truth overlay (red)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during evaluation: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kkk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

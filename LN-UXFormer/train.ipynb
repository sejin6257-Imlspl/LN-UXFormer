{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3090\n",
      "CUDA version: 11.1\n",
      "GPU Memory: 23.69 GB\n",
      "RAM: 269.95 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sejin/anaconda3/envs/kkk/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as D\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from timeit import default_timer as timer\n",
    "import psutil\n",
    "from os.path import join\n",
    "\n",
    "from data_load import Dataset\n",
    "from model.LN_UXFormer import LN_UXFormer\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "root_dir = '/data3/glocal_project/multiclass_seg_kid_ney/data' \n",
    "raw_data_dir = join(root_dir, 'Training')\n",
    "results_dir = '/data3/glocal_project/LN_UXFormer/result_bestmodel'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print('CUDA version:', torch.version.cuda)\n",
    "    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB')\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'RAM: {round(psutil.virtual_memory()[0]/1000000000, 2)} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seg_loaders(data, batch_size):\n",
    "    N = len(data)\n",
    "    N_train = int(0.9 * N)\n",
    "    N_dev = N - N_train\n",
    "    \n",
    "    print(f'Total: {N}, Train: {N_train}, Validation: {N_dev}')\n",
    "    \n",
    "    train_data, dev_data = D.random_split(data, [N_train, N_dev])\n",
    "    \n",
    "    train_loader = D.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    dev_loader = D.DataLoader(dev_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    print(f'Train batches: {len(train_loader)}, Validation batches: {len(dev_loader)}')\n",
    "    \n",
    "    return train_loader, dev_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2497 valid image pairs\n",
      "Skipped 1 pairs with empty masks\n",
      "Total: 2497, Train: 2247, Validation: 250\n",
      "Train batches: 141, Validation batches: 16\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "dataset = Dataset(raw_data_dir)\n",
    "\n",
    "train_loader, dev_loader = make_seg_loaders(dataset, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sejin/anaconda3/envs/kkk/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "seg_model = LN_UXFormer(n_channels=1, n_classes=1).to(device)\n",
    "\n",
    "optimizers = {\n",
    "    'main': optim.AdamW(seg_model.parameters(), lr=1e-3)\n",
    "}\n",
    "\n",
    "schedulers = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizers['main'],\n",
    "    mode='min',\n",
    "    factor=0.9,\n",
    "    patience=3,\n",
    "    verbose=True,\n",
    "    min_lr=1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_dice_loss_sigmoid(pred, target, smooth=1e-6):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    pred_flat = pred.reshape(pred.size(0), -1)\n",
    "    target_flat = target.reshape(target.size(0), -1)\n",
    "    \n",
    "    intersection = (pred_flat * target_flat).sum(dim=1)\n",
    "    union = pred_flat.sum(dim=1) + target_flat.sum(dim=1)\n",
    "    \n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    loss = 1 - dice.mean()\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def combined_binary_loss_sigmoid(pred, target, dice_weight=0.95, ce_weight=0.05):\n",
    "    dice = binary_dice_loss_sigmoid(pred, target)\n",
    "    \n",
    "    bce_loss = nn.BCEWithLogitsLoss()\n",
    "    pred_reshaped = pred.view(pred.size(0), -1)\n",
    "    target_reshaped = target.view(target.size(0), -1)\n",
    "    ce = bce_loss(pred_reshaped, target_reshaped)\n",
    "    \n",
    "    total_loss = dice_weight * dice + ce_weight * ce\n",
    "    \n",
    "    return total_loss, dice.item(), ce.item()\n",
    "\n",
    "\n",
    "def train_epoch(seg_model, optimizers, train_loader, epoch):\n",
    "    seg_model.train()\n",
    "    total_loss = 0\n",
    "    total_dice_value = 0\n",
    "    total_ce_value = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        flair, seg = batch\n",
    "        flair = flair.to(device)\n",
    "        seg = seg.to(device)\n",
    "        \n",
    "        if isinstance(optimizers, dict):\n",
    "            for optimizer in optimizers.values():\n",
    "                optimizer.zero_grad()\n",
    "        else:\n",
    "            optimizers.zero_grad()\n",
    "            \n",
    "        output = seg_model(flair)\n",
    "        dice_loss, dice_value, ce_value = combined_binary_loss_sigmoid(output, seg)\n",
    "        \n",
    "        total_dice_value += dice_value\n",
    "        total_ce_value += ce_value\n",
    "        \n",
    "        loss = torch.mean(dice_loss)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if isinstance(optimizers, dict):\n",
    "            for optimizer in optimizers.values():\n",
    "                optimizer.step()\n",
    "        else:\n",
    "            optimizers.step()\n",
    "        \n",
    "    avg_dice_value = total_dice_value / len(train_loader)\n",
    "    avg_ce_value = total_ce_value / len(train_loader)   \n",
    "    \n",
    "    print(f'Train - Dice Loss: {avg_dice_value:.4f}, CE Loss: {avg_ce_value:.4f}, Combined Loss: {total_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def evaluate(seg_model, dev_loader, epoch, schedulers): \n",
    "    seg_model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_dice_value = 0\n",
    "    total_ce_value = 0\n",
    "    total_dice_score = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dev_loader:\n",
    "            flair, y = batch\n",
    "            flair = flair.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            output = seg_model(flair)\n",
    "            dice_loss, dice_value, ce_value = combined_binary_loss_sigmoid(output, y)\n",
    "            \n",
    "            total_dice_value += dice_value\n",
    "            total_ce_value += ce_value\n",
    "            \n",
    "            dice_score = 1 - binary_dice_loss_sigmoid(output, y)\n",
    "            total_dice_score += dice_score \n",
    "            \n",
    "            loss = torch.mean(dice_loss)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dev_loader)\n",
    "    avg_dice_score = total_dice_score / len(dev_loader)\n",
    "    avg_dice_value = total_dice_value / len(dev_loader)\n",
    "    avg_ce_value = total_ce_value / len(dev_loader)\n",
    "        \n",
    "    print(f'Validation - Epoch {epoch}')\n",
    "    print(f'Dice Score: {avg_dice_score:.4f}')\n",
    "    print(f'Dice Loss: {avg_dice_value:.4f}, CE Loss: {avg_ce_value:.4f}, Combined Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    if isinstance(schedulers, dict):\n",
    "        for scheduler in schedulers.values():\n",
    "            scheduler.step(avg_loss)\n",
    "    else:\n",
    "        schedulers.step(avg_loss)\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Dice Loss: 0.8671, CE Loss: 1.1552, Combined Loss: 0.8815\n",
      "Validation - Epoch 1\n",
      "Dice Score: 0.2311\n",
      "Dice Loss: 0.7689, CE Loss: 1.4558, Combined Loss: 0.8033\n",
      "Best model saved with loss: 0.8033\n",
      "Epoch 1: Train Loss: 0.8815, Valid Loss: 0.8033, Time: 74.393s\n",
      "\n",
      "Train - Dice Loss: 0.7440, CE Loss: 0.7979, Combined Loss: 0.7467\n",
      "Validation - Epoch 2\n",
      "Dice Score: 0.2723\n",
      "Dice Loss: 0.7277, CE Loss: 0.5146, Combined Loss: 0.7171\n",
      "Best model saved with loss: 0.7171\n",
      "Epoch 2: Train Loss: 0.7467, Valid Loss: 0.7171, Time: 73.878s\n",
      "\n",
      "Train - Dice Loss: 0.6361, CE Loss: 0.2753, Combined Loss: 0.6180\n",
      "Validation - Epoch 3\n",
      "Dice Score: 0.4333\n",
      "Dice Loss: 0.5667, CE Loss: 0.2068, Combined Loss: 0.5487\n",
      "Best model saved with loss: 0.5487\n",
      "Epoch 3: Train Loss: 0.6180, Valid Loss: 0.5487, Time: 76.259s\n",
      "\n",
      "Train - Dice Loss: 0.5330, CE Loss: 0.2114, Combined Loss: 0.5169\n",
      "Validation - Epoch 4\n",
      "Dice Score: 0.4984\n",
      "Dice Loss: 0.5016, CE Loss: 0.1571, Combined Loss: 0.4844\n",
      "Best model saved with loss: 0.4844\n",
      "Epoch 4: Train Loss: 0.5169, Valid Loss: 0.4844, Time: 73.423s\n",
      "\n",
      "Train - Dice Loss: 0.4958, CE Loss: 0.1951, Combined Loss: 0.4807\n",
      "Validation - Epoch 5\n",
      "Dice Score: 0.5307\n",
      "Dice Loss: 0.4693, CE Loss: 0.1052, Combined Loss: 0.4511\n",
      "Best model saved with loss: 0.4511\n",
      "Epoch 5: Train Loss: 0.4807, Valid Loss: 0.4511, Time: 73.229s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_epochs = 1000\n",
    "train_losses = []\n",
    "dev_losses = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    for epoch in range(1, total_epochs + 1):\n",
    "        start_time = timer()\n",
    "        \n",
    "        train_loss = train_epoch(seg_model, optimizers, train_loader, epoch)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        dev_loss = evaluate(seg_model, dev_loader, epoch, schedulers)\n",
    "        dev_losses.append(dev_loss)\n",
    "        \n",
    "        end_time = timer()\n",
    "        \n",
    "        torch.save(seg_model.state_dict(), \n",
    "                  join(results_dir, f'LN_UXFormer_epoch_{epoch}.pt'))\n",
    "        \n",
    "        if dev_loss < best_loss:\n",
    "            best_loss = dev_loss\n",
    "            torch.save(seg_model.state_dict(), \n",
    "                      join(results_dir, 'LN_UXFormer_epoch.pt'))\n",
    "            print(f'Best model saved with loss: {best_loss:.4f}')\n",
    "        \n",
    "        print(f'Epoch {epoch}: Train Loss: {train_loss:.4f}, Valid Loss: {dev_loss:.4f}, Time: {(end_time - start_time):.3f}s\\n')\n",
    "    \n",
    "    print('Training completed.')\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print('Training interrupted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kkk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

# LN-UXFormer: Local and Non-Local U-Net Cross Transformer Fusion Network
<img width="1240" height="598" alt="image" src="https://github.com/user-attachments/assets/749646b8-0c05-41db-8c1b-77d64da2186b" />
## ğŸ“‹ Overview
A bidirectional interactive learning framework that establishes explicit parallel pathways for mutual information exchange between local feature extraction (U-Net) and non-local contextual modeling (Transformer) for medical image segmentation.
## ğŸš€ Key Features
- âœ… Bidirectional CNN-Transformer fusion
- âœ… Cross-Attention (XATTN) for local-to-non-local transfer
- âœ… Cross CBAM (XCBAM) for non-local-to-local transfer
- âœ… Multi-scale feature integration
- âœ… State-of-the-art performance on 5 medical datasets
## Result 
<img width="1183" height="676" alt="image" src="https://github.com/user-attachments/assets/917bcef1-3080-4839-98ef-728acd817521" />
<img width="767" height="355" alt="image" src="https://github.com/user-attachments/assets/3f2db718-03ea-4bb3-8f00-e20ee10b15f0" />

<img width="1183" height="298" alt="image" src="https://github.com/user-attachments/assets/04c8f70f-b955-4ebe-b8f9-fb1b34f1d603" />
<img width="759" height="258" alt="image" src="https://github.com/user-attachments/assets/c8b94113-7222-46f3-b986-1984771ffa3c" />


### Training
Open and run 'train.ipynb':
from data_load import Dataset
from model.LN_UXFormer import LN_UXFormer
model = LNUXFormer(in_channels=1, num_classes=1)

### Testing
Open and run 'test.ipynb':
# Load checkpoint and evaluate
checkpoint = torch.load(model_path)
model.load_state_dict(checkpoint)

## ğŸ™ Acknowledgments
This work was supported by:
- National Research Foundation of Korea (NRF) grant (RS-2024-00357917)
- IITP - Innovative Human Resource Development for Local Intellectualization (IITP-2025-RS-2022-00156287)
- IITP - ICAN program (IITP-2025-RS-2022-00156385)
- 
## ğŸ“„ License
MIT License - see [LICENSE](LICENSE) file for details.

